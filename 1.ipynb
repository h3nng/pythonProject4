{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据预处理\n",
    "\n",
    "# 导入相关库\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 读取数据\n",
    "data = pd.read_csv('data.csv')\n",
    "\n",
    "\n",
    "# 数据预处理\n",
    "# 1. 缺失值处理\n",
    "\n",
    "# 2. 异常值处理     \n",
    "# 3. 特征工程     \n",
    "# 4. 数据集划分     \n",
    "# 5. 特征选择     \n",
    "# 6. 模型训练     \n",
    "# 7. 模型评估     \n",
    "# 8. 模型预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据预处理\n",
    "# 导入数据并显示前6行数据来检查数据是否正确\n",
    "df = pd.read_csv('死亡人数.csv',encoding='gbk')\n",
    "bf = pd.read_csv('出生人数.csv',encoding='gbk')\n",
    "pf = pd.read_csv('population-and-demography.csv',encoding='gbk')\n",
    "pd.set_option('display.max_columns',100000)\n",
    "display(df.head(6))\n",
    "display(bf.head(6))\n",
    "display(pf.head(6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 合并数据集\n",
    "df = df.set_index(['Country name', 'Year'], drop=True)\n",
    "bf = bf.set_index(['Country name', 'Year'], drop=True)\n",
    "pf = pf.set_index(['Country name', 'Year'], drop =True)\n",
    "bd = pd.merge(df,bf,on=['Country name','Year'])\n",
    "bd = pd.merge(bd,pf,on=['Country name','Year'])\n",
    "display(bd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义栈结构\n",
    "class Stack(object):\n",
    "    def __init__(self):\n",
    "        self.items = []\n",
    "\n",
    "    def push(self, item):\n",
    "        \"\"\"添加元素到栈顶\"\"\"\n",
    "        self.items.append(item)\n",
    "\n",
    "    def pop(self):\n",
    "        \"\"\"弹出栈顶元素\"\"\"\n",
    "        return self.items.pop()\n",
    "\n",
    "    def is_empty(self):\n",
    "        \"\"\"判断栈是否为空\"\"\"\n",
    "        return len(self.items) == 0\n",
    "\n",
    "    def peek(self):\n",
    "        \"\"\"查看栈顶元素\"\"\"\n",
    "        if not self.is_empty():\n",
    "            return self.items[-1]\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    def size(self):\n",
    "        \"\"\"查看栈的大小\"\"\"\n",
    "        return len(self.items) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[86], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m     data\u001b[38;5;241m.\u001b[39misnull()\u001b[38;5;241m.\u001b[39msum() \u001b[38;5;66;03m# 查看缺失值是否全为0\u001b[39;00m\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m data\n\u001b[1;32m----> 9\u001b[0m bd \u001b[38;5;241m=\u001b[39m data_fill(bd)\n",
      "Cell \u001b[1;32mIn[86], line 6\u001b[0m, in \u001b[0;36mdata_fill\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m data\u001b[38;5;241m.\u001b[39mselect_dtypes(include\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnumber\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39mcolumns:\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m data\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mlevels[\u001b[38;5;241m0\u001b[39m]:\n\u001b[1;32m----> 6\u001b[0m         data\u001b[38;5;241m.\u001b[39mloc[j,i] \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mloc[j,i]\u001b[38;5;241m.\u001b[39minterpolate(method \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcubic\u001b[39m\u001b[38;5;124m'\u001b[39m, order \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m)\n\u001b[0;32m      7\u001b[0m data\u001b[38;5;241m.\u001b[39misnull()\u001b[38;5;241m.\u001b[39msum() \u001b[38;5;66;03m# 查看缺失值是否全为0\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[1;32md:\\conda\\envs\\conda1\\Lib\\site-packages\\pandas\\core\\indexing.py:911\u001b[0m, in \u001b[0;36m_LocationIndexer.__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m    908\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_valid_setitem_indexer(key)\n\u001b[0;32m    910\u001b[0m iloc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miloc\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39miloc\n\u001b[1;32m--> 911\u001b[0m iloc\u001b[38;5;241m.\u001b[39m_setitem_with_indexer(indexer, value, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname)\n",
      "File \u001b[1;32md:\\conda\\envs\\conda1\\Lib\\site-packages\\pandas\\core\\indexing.py:1942\u001b[0m, in \u001b[0;36m_iLocIndexer._setitem_with_indexer\u001b[1;34m(self, indexer, value, name)\u001b[0m\n\u001b[0;32m   1939\u001b[0m \u001b[38;5;66;03m# align and set the values\u001b[39;00m\n\u001b[0;32m   1940\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m take_split_path:\n\u001b[0;32m   1941\u001b[0m     \u001b[38;5;66;03m# We have to operate column-wise\u001b[39;00m\n\u001b[1;32m-> 1942\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setitem_with_indexer_split_path(indexer, value, name)\n\u001b[0;32m   1943\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1944\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setitem_single_block(indexer, value, name)\n",
      "File \u001b[1;32md:\\conda\\envs\\conda1\\Lib\\site-packages\\pandas\\core\\indexing.py:1963\u001b[0m, in \u001b[0;36m_iLocIndexer._setitem_with_indexer_split_path\u001b[1;34m(self, indexer, value, name)\u001b[0m\n\u001b[0;32m   1960\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(value, ABCSeries) \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miloc\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m   1961\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Series\n\u001b[1;32m-> 1963\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_align_series(indexer, Series(value))\n\u001b[0;32m   1965\u001b[0m \u001b[38;5;66;03m# Ensure we have something we can iterate over\u001b[39;00m\n\u001b[0;32m   1966\u001b[0m info_axis \u001b[38;5;241m=\u001b[39m indexer[\u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[1;32md:\\conda\\envs\\conda1\\Lib\\site-packages\\pandas\\core\\indexing.py:2427\u001b[0m, in \u001b[0;36m_iLocIndexer._align_series\u001b[1;34m(self, indexer, ser, multiindex_indexer, using_cow)\u001b[0m\n\u001b[0;32m   2424\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m ser\n\u001b[0;32m   2425\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m ser\u001b[38;5;241m.\u001b[39m_values\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m-> 2427\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ser\u001b[38;5;241m.\u001b[39mreindex(new_ix)\u001b[38;5;241m.\u001b[39m_values\n\u001b[0;32m   2429\u001b[0m \u001b[38;5;66;03m# 2 dims\u001b[39;00m\n\u001b[0;32m   2430\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m single_aligner:\n\u001b[0;32m   2431\u001b[0m     \u001b[38;5;66;03m# reindex along index\u001b[39;00m\n",
      "File \u001b[1;32md:\\conda\\envs\\conda1\\Lib\\site-packages\\pandas\\core\\series.py:5153\u001b[0m, in \u001b[0;36mSeries.reindex\u001b[1;34m(self, index, axis, method, copy, level, fill_value, limit, tolerance)\u001b[0m\n\u001b[0;32m   5136\u001b[0m \u001b[38;5;129m@doc\u001b[39m(\n\u001b[0;32m   5137\u001b[0m     NDFrame\u001b[38;5;241m.\u001b[39mreindex,  \u001b[38;5;66;03m# type: ignore[has-type]\u001b[39;00m\n\u001b[0;32m   5138\u001b[0m     klass\u001b[38;5;241m=\u001b[39m_shared_doc_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mklass\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5151\u001b[0m     tolerance\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   5152\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Series:\n\u001b[1;32m-> 5153\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mreindex(\n\u001b[0;32m   5154\u001b[0m         index\u001b[38;5;241m=\u001b[39mindex,\n\u001b[0;32m   5155\u001b[0m         method\u001b[38;5;241m=\u001b[39mmethod,\n\u001b[0;32m   5156\u001b[0m         copy\u001b[38;5;241m=\u001b[39mcopy,\n\u001b[0;32m   5157\u001b[0m         level\u001b[38;5;241m=\u001b[39mlevel,\n\u001b[0;32m   5158\u001b[0m         fill_value\u001b[38;5;241m=\u001b[39mfill_value,\n\u001b[0;32m   5159\u001b[0m         limit\u001b[38;5;241m=\u001b[39mlimit,\n\u001b[0;32m   5160\u001b[0m         tolerance\u001b[38;5;241m=\u001b[39mtolerance,\n\u001b[0;32m   5161\u001b[0m     )\n",
      "File \u001b[1;32md:\\conda\\envs\\conda1\\Lib\\site-packages\\pandas\\core\\generic.py:5610\u001b[0m, in \u001b[0;36mNDFrame.reindex\u001b[1;34m(self, labels, index, columns, axis, method, copy, level, fill_value, limit, tolerance)\u001b[0m\n\u001b[0;32m   5607\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_multi(axes, copy, fill_value)\n\u001b[0;32m   5609\u001b[0m \u001b[38;5;66;03m# perform the reindex on the axes\u001b[39;00m\n\u001b[1;32m-> 5610\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_axes(\n\u001b[0;32m   5611\u001b[0m     axes, level, limit, tolerance, method, fill_value, copy\n\u001b[0;32m   5612\u001b[0m )\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreindex\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32md:\\conda\\envs\\conda1\\Lib\\site-packages\\pandas\\core\\generic.py:5638\u001b[0m, in \u001b[0;36mNDFrame._reindex_axes\u001b[1;34m(self, axes, level, limit, tolerance, method, fill_value, copy)\u001b[0m\n\u001b[0;32m   5633\u001b[0m new_index, indexer \u001b[38;5;241m=\u001b[39m ax\u001b[38;5;241m.\u001b[39mreindex(\n\u001b[0;32m   5634\u001b[0m     labels, level\u001b[38;5;241m=\u001b[39mlevel, limit\u001b[38;5;241m=\u001b[39mlimit, tolerance\u001b[38;5;241m=\u001b[39mtolerance, method\u001b[38;5;241m=\u001b[39mmethod\n\u001b[0;32m   5635\u001b[0m )\n\u001b[0;32m   5637\u001b[0m axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_axis_number(a)\n\u001b[1;32m-> 5638\u001b[0m obj \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39m_reindex_with_indexers(\n\u001b[0;32m   5639\u001b[0m     {axis: [new_index, indexer]},\n\u001b[0;32m   5640\u001b[0m     fill_value\u001b[38;5;241m=\u001b[39mfill_value,\n\u001b[0;32m   5641\u001b[0m     copy\u001b[38;5;241m=\u001b[39mcopy,\n\u001b[0;32m   5642\u001b[0m     allow_dups\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m   5643\u001b[0m )\n\u001b[0;32m   5644\u001b[0m \u001b[38;5;66;03m# If we've made a copy once, no need to make another one\u001b[39;00m\n\u001b[0;32m   5645\u001b[0m copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32md:\\conda\\envs\\conda1\\Lib\\site-packages\\pandas\\core\\generic.py:5686\u001b[0m, in \u001b[0;36mNDFrame._reindex_with_indexers\u001b[1;34m(self, reindexers, fill_value, copy, allow_dups)\u001b[0m\n\u001b[0;32m   5683\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m ensure_platform_int(indexer)\n\u001b[0;32m   5685\u001b[0m \u001b[38;5;66;03m# TODO: speed up on homogeneous DataFrame objects (see _reindex_multi)\u001b[39;00m\n\u001b[1;32m-> 5686\u001b[0m new_data \u001b[38;5;241m=\u001b[39m new_data\u001b[38;5;241m.\u001b[39mreindex_indexer(\n\u001b[0;32m   5687\u001b[0m     index,\n\u001b[0;32m   5688\u001b[0m     indexer,\n\u001b[0;32m   5689\u001b[0m     axis\u001b[38;5;241m=\u001b[39mbaxis,\n\u001b[0;32m   5690\u001b[0m     fill_value\u001b[38;5;241m=\u001b[39mfill_value,\n\u001b[0;32m   5691\u001b[0m     allow_dups\u001b[38;5;241m=\u001b[39mallow_dups,\n\u001b[0;32m   5692\u001b[0m     copy\u001b[38;5;241m=\u001b[39mcopy,\n\u001b[0;32m   5693\u001b[0m )\n\u001b[0;32m   5694\u001b[0m \u001b[38;5;66;03m# If we've made a copy once, no need to make another one\u001b[39;00m\n\u001b[0;32m   5695\u001b[0m copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32md:\\conda\\envs\\conda1\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:680\u001b[0m, in \u001b[0;36mBaseBlockManager.reindex_indexer\u001b[1;34m(self, new_axis, indexer, axis, fill_value, allow_dups, copy, only_slice, use_na_proxy)\u001b[0m\n\u001b[0;32m    677\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRequested axis not found in manager\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    679\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 680\u001b[0m     new_blocks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_slice_take_blocks_ax0(\n\u001b[0;32m    681\u001b[0m         indexer,\n\u001b[0;32m    682\u001b[0m         fill_value\u001b[38;5;241m=\u001b[39mfill_value,\n\u001b[0;32m    683\u001b[0m         only_slice\u001b[38;5;241m=\u001b[39monly_slice,\n\u001b[0;32m    684\u001b[0m         use_na_proxy\u001b[38;5;241m=\u001b[39muse_na_proxy,\n\u001b[0;32m    685\u001b[0m     )\n\u001b[0;32m    686\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    687\u001b[0m     new_blocks \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    688\u001b[0m         blk\u001b[38;5;241m.\u001b[39mtake_nd(\n\u001b[0;32m    689\u001b[0m             indexer,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    695\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m blk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks\n\u001b[0;32m    696\u001b[0m     ]\n",
      "File \u001b[1;32md:\\conda\\envs\\conda1\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:773\u001b[0m, in \u001b[0;36mBaseBlockManager._slice_take_blocks_ax0\u001b[1;34m(self, slice_or_indexer, fill_value, only_slice, use_na_proxy, ref_inplace_op)\u001b[0m\n\u001b[0;32m    770\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    771\u001b[0m             bp \u001b[38;5;241m=\u001b[39m BlockPlacement(\u001b[38;5;28mslice\u001b[39m(\u001b[38;5;241m0\u001b[39m, sllen))\n\u001b[0;32m    772\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[1;32m--> 773\u001b[0m                 blk\u001b[38;5;241m.\u001b[39mtake_nd(\n\u001b[0;32m    774\u001b[0m                     slobj,\n\u001b[0;32m    775\u001b[0m                     axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m,\n\u001b[0;32m    776\u001b[0m                     new_mgr_locs\u001b[38;5;241m=\u001b[39mbp,\n\u001b[0;32m    777\u001b[0m                     fill_value\u001b[38;5;241m=\u001b[39mfill_value,\n\u001b[0;32m    778\u001b[0m                 )\n\u001b[0;32m    779\u001b[0m             ]\n\u001b[0;32m    781\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sl_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mslice\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    782\u001b[0m     blknos \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblknos[slobj]\n",
      "File \u001b[1;32md:\\conda\\envs\\conda1\\Lib\\site-packages\\pandas\\core\\internals\\blocks.py:1307\u001b[0m, in \u001b[0;36mBlock.take_nd\u001b[1;34m(self, indexer, axis, new_mgr_locs, fill_value)\u001b[0m\n\u001b[0;32m   1304\u001b[0m     allow_fill \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   1306\u001b[0m \u001b[38;5;66;03m# Note: algos.take_nd has upcast logic similar to coerce_to_target_dtype\u001b[39;00m\n\u001b[1;32m-> 1307\u001b[0m new_values \u001b[38;5;241m=\u001b[39m algos\u001b[38;5;241m.\u001b[39mtake_nd(\n\u001b[0;32m   1308\u001b[0m     values, indexer, axis\u001b[38;5;241m=\u001b[39maxis, allow_fill\u001b[38;5;241m=\u001b[39mallow_fill, fill_value\u001b[38;5;241m=\u001b[39mfill_value\n\u001b[0;32m   1309\u001b[0m )\n\u001b[0;32m   1311\u001b[0m \u001b[38;5;66;03m# Called from three places in managers, all of which satisfy\u001b[39;00m\n\u001b[0;32m   1312\u001b[0m \u001b[38;5;66;03m#  these assertions\u001b[39;00m\n\u001b[0;32m   1313\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ExtensionBlock):\n\u001b[0;32m   1314\u001b[0m     \u001b[38;5;66;03m# NB: in this case, the 'axis' kwarg will be ignored in the\u001b[39;00m\n\u001b[0;32m   1315\u001b[0m     \u001b[38;5;66;03m#  algos.take_nd call above.\u001b[39;00m\n",
      "File \u001b[1;32md:\\conda\\envs\\conda1\\Lib\\site-packages\\pandas\\core\\array_algos\\take.py:117\u001b[0m, in \u001b[0;36mtake_nd\u001b[1;34m(arr, indexer, axis, fill_value, allow_fill)\u001b[0m\n\u001b[0;32m    114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mtake(indexer, fill_value\u001b[38;5;241m=\u001b[39mfill_value, allow_fill\u001b[38;5;241m=\u001b[39mallow_fill)\n\u001b[0;32m    116\u001b[0m arr \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(arr)\n\u001b[1;32m--> 117\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _take_nd_ndarray(arr, indexer, axis, fill_value, allow_fill)\n",
      "File \u001b[1;32md:\\conda\\envs\\conda1\\Lib\\site-packages\\pandas\\core\\array_algos\\take.py:162\u001b[0m, in \u001b[0;36m_take_nd_ndarray\u001b[1;34m(arr, indexer, axis, fill_value, allow_fill)\u001b[0m\n\u001b[0;32m    157\u001b[0m     out \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mempty(out_shape, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m    159\u001b[0m func \u001b[38;5;241m=\u001b[39m _get_take_nd_function(\n\u001b[0;32m    160\u001b[0m     arr\u001b[38;5;241m.\u001b[39mndim, arr\u001b[38;5;241m.\u001b[39mdtype, out\u001b[38;5;241m.\u001b[39mdtype, axis\u001b[38;5;241m=\u001b[39maxis, mask_info\u001b[38;5;241m=\u001b[39mmask_info\n\u001b[0;32m    161\u001b[0m )\n\u001b[1;32m--> 162\u001b[0m func(arr, indexer, out, fill_value)\n\u001b[0;32m    164\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m flip_order:\n\u001b[0;32m    165\u001b[0m     out \u001b[38;5;241m=\u001b[39m out\u001b[38;5;241m.\u001b[39mT\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 数据清洗\n",
    "def data_fill(data):\n",
    "    data.isnull().sum() # 查看缺失值\n",
    "    # 用插值法填充缺失值\n",
    "    data.isnull().sum() # 查看缺失值是否全为0\n",
    "    return data\n",
    "bd = data_fill(bd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 清洗字符串格式\n",
    "import dis\n",
    "import re\n",
    "\n",
    "from numpy import disp\n",
    "for i in bd.columns:\n",
    "    if bd[i].dtype == 'object':\n",
    "        bd[i] = bd[i].apply(lambda x: re.sub(r'[^\\w\\s]','',x))\n",
    "\n",
    "# 显示数据\n",
    "pd.set_option('display.max_columns',100)\n",
    "display(bd.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据分析\n",
    "# 总览分析\n",
    "# 计算全球总出生人数和总死亡人数\n",
    "total_birth = bd.loc[('World'), 'Births'].astype('float64').sum() # type: ignore\n",
    "display(total_birth)\n",
    "total_death = bd.loc[('World'), 'Deaths'].astype('float64').sum() # type: ignore\n",
    "display(total_death)\n",
    "# 计算各国的总出生人数和总死亡人数\n",
    "index = bd.index.levels[0] # type: ignore  levels在新版本pandas中被移除\n",
    "display(index)\n",
    "a = []\n",
    "b = []\n",
    "for i in index:\n",
    "    values = bd.loc[i, 'Births'].astype('float64').sum() # type: ignore\n",
    "    values2 = bd.loc[i, 'Deaths'].astype('float64').sum() # type: ignore\n",
    "    b.append(values2)\n",
    "    a.append(values)\n",
    "pd.set_option('display.float_format', lambda x: '{:f}'.format(x))  # 将 '{:f}' 替换为您所需的格式\n",
    "births_sum = pd.Series(a, index=index) \n",
    "deaths_sum = pd.Series(b, index=index) \n",
    "bd_sum = pd.DataFrame({'Births_sum': births_sum, 'Deaths_sum': deaths_sum})\n",
    "display(bd_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 排序并输出死亡人数,出生人数的前十国家\n",
    "bd_sum.sort_values(by='Births_sum', ascending=False, inplace=True)\n",
    "b_country = bd_sum.head(10).index\n",
    "print(\"出生人数前十:\")\n",
    "display(b_country)\n",
    "bd_sum.sort_values(by='Deaths_sum', ascending=False, inplace=True)\n",
    "d_country = bd_sum.head(10).index\n",
    "print(\"死亡人数前十:\")\n",
    "display(d_country)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#时间序列分析\n",
    "# 分析全球每年出生人数和死亡人数的变化趋势\n",
    "def data_select(Country_name):\n",
    "    bds = data_fill(bd.loc[Country_name, ['Births', 'Deaths','Population']])\n",
    "    bds['births_rate'] = bds['Births']/bds['Population']\n",
    "    bds['deaths_rate'] = bds['Deaths']/bds['Population']\n",
    "    display(Country_name)\n",
    "    display(bds.describe(include='all'))\n",
    "    bds[['Births', 'Deaths']].plot(figsize=(12, 6))# 绘制Births_Deaths折线图\n",
    "    plt.title('Births_Deaths')\n",
    "    plt.show()\n",
    "    bds[['births_rate', 'deaths_rate']].plot(figsize=(12, 6))# 绘制births_rate_deaths_rate折线图\n",
    "    plt.title('births_rate_deaths_rate')\n",
    "    plt.show()\n",
    "data_select('World')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = ['China', 'India', 'United States','United Kingdom']\n",
    "for i in index:# 分析美国,印度,美国,英国的出生人数趋势\n",
    "    data_select(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 统计分析\n",
    "# 使用NumPy计算全球和各国的出生率和死亡率\n",
    "def bd_rates(Coutry_name,idea):\n",
    "    temp1 = np.array(bd.loc[Coutry_name, idea])\n",
    "    temp2 = np.array(bd.loc[Coutry_name, 'Populatioon'])\n",
    "    temp = temp1/temp2\n",
    "    return [np.mean(temp), np.median(temp), np.std(temp), np.var(temp), np.min(temp), np.max(temp)]\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
